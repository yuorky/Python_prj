{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DogCat(data.Dataset):\n",
    "    def __init__(self, root):\n",
    "        imgs = os.listdir(root)\n",
    "        # 所有图片的绝对路径\n",
    "        # 这里不实际加载图片，只是指定路径，当调用__getitem__时才会真正读图片\n",
    "        self.imgs = [os.path.join(root, img) for img in imgs]\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.imgs[index]\n",
    "        # dog->1， cat->0\n",
    "        label = 1 if 'dog' in img_path.split('/')[-1] else 0\n",
    "        pil_img = Image.open(img_path)\n",
    "        array = np.asarray(pil_img)\n",
    "        data = t.from_numpy(array)\n",
    "        return data, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DogCat('./data/dogcat/')\n",
    "img, label = dataset[0] # 相当于调用dataset.__getitem__(0)\n",
    "for img, label in dataset:\n",
    "    print(img.size(), img.float().mean(), label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 用torchvision实现对PIL image和Tensor的常用操作 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torchvision import transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.Compose([\n",
    "    T.Resize(224),# 缩放图片(Image)，保持长宽比不变，最短边为224像素\n",
    "    T.CenterCrop(224), # 从图片中间切出224*224的图片\n",
    "    T.ToTensor(), #将图片(Image)转成Tensor，归一化至[0, 1]\n",
    "    T.Normalize(mean=[.5,.5,.5],std=[.5,.5,.5])# 标准化至[-1, 1]，规定均值和标准差 \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DogCat(data.Dataset):\n",
    "    def __init__(self,root,transforms=None):\n",
    "        imgs = os.listdir(root) #得到在root下所有的images\n",
    "        self.imgs = [os.path.join(root,img) for img in imgs] #建立images的path： root/image\n",
    "        self.tranforms=transforms\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        img_path = self.imgs[index]\n",
    "        label = 0 if 'dog' in img_path.split('/')[-1] else 1\n",
    "        data = Image.open(img_path)\n",
    "        if self.transforms:\n",
    "            data = self.transforms(data)\n",
    "        return data, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DogCat('./data/dogcat',transforms = transform)\n",
    "img, label = dataset[0]\n",
    "for img,label in dataset:\n",
    "    print(img.size(),label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import imageFolder\n",
    "dataset = ImageFolder('data/dogcat_2/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 没有任何的transform，所以返回的还是PIL Image对象\n",
    "dataset[0][1] # 第一维是第几张图，第二维为1返回label\n",
    "dataset[0][0] # 为0返回图片数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加上transform\n",
    "normalize = T.Normalize(mean=[0.4, 0.4, 0.4], std=[0.2, 0.2, 0.2])\n",
    "transform  = T.Compose([\n",
    "         T.RandomResizedCrop(224),\n",
    "         T.RandomHorizontalFlip(),\n",
    "         T.ToTensor(),\n",
    "         normalize,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ImageFolder('data/dogcat_2/', transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 深度学习中图片数据一般保存成CxHxW，即通道数x图片高x图片宽\n",
    "dataset[0][0].size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=3,shuffle=True, num_workers=0,drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(dataloader)\n",
    "imgs.labels = next(dataiter)\n",
    "imgs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewDogCat(DogCat):\n",
    "    def __getitem__(self, index):\n",
    "        try:\n",
    "            return super(NewDogCat,self).__getitem__(index)\n",
    "        except:\n",
    "            return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataloader import default_collate\n",
    "def my_collate_fn(batch):\n",
    "    '''\n",
    "    batch中每个元素形如(data, label)\n",
    "    '''\n",
    "    # 过滤为None的数据\n",
    "    batch = list(filter(lambda x:x[0] is not None, batch))\n",
    "    if len(batch) == 0: return t.Tensor()\n",
    "    return default_collate(batch) # 用默认方式拼接过滤后的batch数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = NewDogCat('data/dogcat_wrong/', transforms=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, 2, collate_fn=my_collate_fn, num_workers=1,shuffle=True)\n",
    "for batch_datas, batch_labels in dataloader:\n",
    "    print(batch_datas.size(),batch_labels.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 视觉工具包： torchvision "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/squeezenet1_1-f364aa15.pth\" to C:\\Users\\y63qiu/.cache\\torch\\checkpoints\\squeezenet1_1-f364aa15.pth\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "resnet34 = models.squeezenet1_1(pretrained=True, num_classes=1000)\n",
    "\n",
    "resnet34.fc = nn.Linear(512,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.1%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1.0%5%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST\\raw\\train-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST\\raw\\train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "180.4%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST\\raw\\t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets\n",
    "dataset = datasets.MNIST('data/', download=True, train=False, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64 at 0x1B284748>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "to_pil = transforms.ToPILImage()\n",
    "to_pil(t.randn(3,64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "output with shape [1, 224, 224] doesn't match the broadcast shape [3, 224, 224]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-13376f90fd69>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmake_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_image\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdataiter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_grid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataiter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 拼成4*4网格图片，且会转成３通道\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mto_img\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\yorkml\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    558\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# same-process loading\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m             \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    561\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\yorkml\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    558\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# same-process loading\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m             \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    561\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\yorkml\\lib\\site-packages\\torchvision\\datasets\\mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\yorkml\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\yorkml\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, tensor)\u001b[0m\n\u001b[0;32m    162\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mNormalized\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m         \"\"\"\n\u001b[1;32m--> 164\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\yorkml\\lib\\site-packages\\torchvision\\transforms\\functional.py\u001b[0m in \u001b[0;36mnormalize\u001b[1;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[0mmean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m     \u001b[0mstd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m     \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiv_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: output with shape [1, 224, 224] doesn't match the broadcast shape [3, 224, 224]"
     ]
    }
   ],
   "source": [
    "dataloader = DataLoader(dataset, shuffle=True, batch_size=16)\n",
    "from torchvision.utils import make_grid, save_image\n",
    "dataiter = iter(dataloader)\n",
    "img = make_grid(next(dataiter)[0], 4) # 拼成4*4网格图片，且会转成３通道\n",
    "to_img(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 可视化工具 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorboard "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建logger对象，logdir用来指定log文件的保存路径\n",
    "# flush_secs用来指定刷新同步间隔\n",
    "logger = SummaryWriter(log_dir='experimient_cnn', flush_secs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii in range(100):\n",
    "    logger.add_scalar('data/loss',10-ii**0.5)\n",
    "    logger.add_scalar('data/accuracy',ii**0.5/10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visdom "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU加速 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = t.Tensor(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = tensor.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "module = nn.Linear(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=3, out_features=4, bias=True)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=3, out_features=4, bias=True)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module.weight.is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VeryBigModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(veryBigModule,self).__init__()\n",
    "        self.GiantParameter = t.nn.Parameter(t.randn(100000,20000)).cuda()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.GlantParameter1.mm(x.cuda())\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 交叉熵损失函数，带权重\n",
    "criterion = t.nn.CrossEntropyLoss(weight=t.Tensor([1,3]))\n",
    "input = t.randn(4,2).cuda()\n",
    "target = t.Tensor([1,0,0,1]).long().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion.cuda()\n",
    "loss = criterion(input,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight', tensor([1., 3.], device='cuda:0'))])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion._buffers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\y63qiu\\AppData\\Local\\Continuum\\anaconda3\\envs\\yorkml\\lib\\site-packages\\requests\\packages\\urllib3\\connection.py\", line 141, in _new_conn\n",
      "    (self.host, self.port), self.timeout, **extra_kw)\n",
      "  File \"C:\\Users\\y63qiu\\AppData\\Local\\Continuum\\anaconda3\\envs\\yorkml\\lib\\site-packages\\requests\\packages\\urllib3\\util\\connection.py\", line 83, in create_connection\n",
      "    raise err\n",
      "  File \"C:\\Users\\y63qiu\\AppData\\Local\\Continuum\\anaconda3\\envs\\yorkml\\lib\\site-packages\\requests\\packages\\urllib3\\util\\connection.py\", line 73, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [WinError 10061] No connection could be made because the target machine actively refused it\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\y63qiu\\AppData\\Local\\Continuum\\anaconda3\\envs\\yorkml\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py\", line 600, in urlopen\n",
      "    chunked=chunked)\n",
      "  File \"C:\\Users\\y63qiu\\AppData\\Local\\Continuum\\anaconda3\\envs\\yorkml\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py\", line 356, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"C:\\Users\\y63qiu\\AppData\\Local\\Continuum\\anaconda3\\envs\\yorkml\\lib\\http\\client.py\", line 1107, in request\n",
      "    self._send_request(method, url, body, headers)\n",
      "  File \"C:\\Users\\y63qiu\\AppData\\Local\\Continuum\\anaconda3\\envs\\yorkml\\lib\\http\\client.py\", line 1152, in _send_request\n",
      "    self.endheaders(body)\n",
      "  File \"C:\\Users\\y63qiu\\AppData\\Local\\Continuum\\anaconda3\\envs\\yorkml\\lib\\http\\client.py\", line 1103, in endheaders\n",
      "    self._send_output(message_body)\n",
      "  File \"C:\\Users\\y63qiu\\AppData\\Local\\Continuum\\anaconda3\\envs\\yorkml\\lib\\http\\client.py\", line 934, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"C:\\Users\\y63qiu\\AppData\\Local\\Continuum\\anaconda3\\envs\\yorkml\\lib\\http\\client.py\", line 877, in send\n",
      "    self.connect()\n",
      "  File \"C:\\Users\\y63qiu\\AppData\\Local\\Continuum\\anaconda3\\envs\\yorkml\\lib\\site-packages\\requests\\packages\\urllib3\\connection.py\", line 166, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"C:\\Users\\y63qiu\\AppData\\Local\\Continuum\\anaconda3\\envs\\yorkml\\lib\\site-packages\\requests\\packages\\urllib3\\connection.py\", line 150, in _new_conn\n",
      "    self, \"Failed to establish a new connection: %s\" % e)\n",
      "requests.packages.urllib3.exceptions.NewConnectionError: <requests.packages.urllib3.connection.HTTPConnection object at 0x000000000487AC18>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\y63qiu\\AppData\\Local\\Continuum\\anaconda3\\envs\\yorkml\\lib\\site-packages\\requests\\adapters.py\", line 423, in send\n",
      "    timeout=timeout\n",
      "  File \"C:\\Users\\y63qiu\\AppData\\Local\\Continuum\\anaconda3\\envs\\yorkml\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.py\", line 649, in urlopen\n",
      "    _stacktrace=sys.exc_info()[2])\n",
      "  File \"C:\\Users\\y63qiu\\AppData\\Local\\Continuum\\anaconda3\\envs\\yorkml\\lib\\site-packages\\requests\\packages\\urllib3\\util\\retry.py\", line 376, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "requests.packages.urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /env/test1 (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x000000000487AC18>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it',))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\y63qiu\\AppData\\Local\\Continuum\\anaconda3\\envs\\yorkml\\lib\\site-packages\\visdom\\__init__.py\", line 711, in _send\n",
      "    data=json.dumps(msg),\n",
      "  File \"C:\\Users\\y63qiu\\AppData\\Local\\Continuum\\anaconda3\\envs\\yorkml\\lib\\site-packages\\visdom\\__init__.py\", line 677, in _handle_post\n",
      "    r = self.session.post(url, data=data)\n",
      "  File \"C:\\Users\\y63qiu\\AppData\\Local\\Continuum\\anaconda3\\envs\\yorkml\\lib\\site-packages\\requests\\sessions.py\", line 535, in post\n",
      "    return self.request('POST', url, data=data, json=json, **kwargs)\n",
      "  File \"C:\\Users\\y63qiu\\AppData\\Local\\Continuum\\anaconda3\\envs\\yorkml\\lib\\site-packages\\requests\\sessions.py\", line 488, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"C:\\Users\\y63qiu\\AppData\\Local\\Continuum\\anaconda3\\envs\\yorkml\\lib\\site-packages\\requests\\sessions.py\", line 609, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"C:\\Users\\y63qiu\\AppData\\Local\\Continuum\\anaconda3\\envs\\yorkml\\lib\\site-packages\\requests\\adapters.py\", line 487, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /env/test1 (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x000000000487AC18>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it',))\n",
      "Without the incoming socket you cannot receive events from the server or register event handlers to your Visdom client.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception in user code:\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import visdom\n",
    "\n",
    "vis = visdom.Visdom(env=u'test1',use_incoming_socket=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.line(X=x,Y=y,win='sinx',opts={'title':'y'})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
